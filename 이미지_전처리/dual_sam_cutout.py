# -*- coding: utf-8 -*-
"""
YOLO â†’ SAM ì»·ì•„ì›ƒ ìë™í™” (dual mode + directory mirroring)
======================================================
1ï¸âƒ£ YOLOê°€ fruit box/mask íƒì§€
2ï¸âƒ£ SAMì´ YOLO boxë¥¼ seedë¡œ ë°›ì•„ ì •ë°€ ê²½ê³„ ìƒì„±
3ï¸âƒ£ ë‘ ê°€ì§€ ë²„ì „ ë™ì‹œ ì €ì¥:
    - crop ì¤‘ì‹¬í˜• (ê³¼ì¼ ì¤‘ì‹¬)
    - full-maskí˜• (ì›ë³¸ í¬ê¸° ìœ ì§€)
4ï¸âƒ£ ì›ë³¸ images_allì˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ cutout_resultsì—ë„ ê·¸ëŒ€ë¡œ ìœ ì§€
"""

import os
import cv2
import torch
import numpy as np
from ultralytics import YOLO
from segment_anything import sam_model_registry, SamPredictor
from tqdm import tqdm

# ===============================================
# ì„¤ì •
# ===============================================

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ (ì˜ˆ: ~/sam_yolo/melon)
current_dir = os.path.dirname(os.path.abspath(__file__))

# í´ë” ì´ë¦„ì„ fruit ì´ë¦„ìœ¼ë¡œ ì‚¬ìš© (ì˜ˆ: melon)
fruit = os.path.basename(current_dir)  # â† sam_yoloê°€ ì•„ë‹ˆë¼ melonì´ ë˜ë„ë¡ ìˆ˜ì •

# ê°€ì¤‘ì¹˜ / ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
YOLO_WEIGHT = "./runs/segment/train/weights/yolo_melon.pt"
SAM_BASE_CKPT = "./checkpoints/sam_vit_b_01ec64.pth"
SAM_MODEL_TYPE = "vit_b"
SAM_DECODER_PTH = f"./checkpoints/sam_mask_decoder_{fruit}_final.pth"

# ì…ë ¥ / ì¶œë ¥ ë””ë ‰í† ë¦¬ (WSLì—ì„œ Windows D: ë“œë¼ì´ë¸Œ ì‚¬ìš©)
# INPUT_DIR = "./images_all"
INPUT_DIR = "images_all"
# OUTPUT_DIR = "./cutout_results"
OUTPUT_DIR = "images_all_cutout"

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
print("torch.cuda.is_available() =", torch.cuda.is_available())
print("Selected device            =", device)

# ===============================================
# ëª¨ë¸ ë¡œë“œ
# ===============================================
print(f"ğŸš€ Loading YOLO + SAM models for '{fruit}'...")

# YOLO ë¡œë“œ
yolo = YOLO(YOLO_WEIGHT)
# í•„ìš” ì‹œ, ëª…ì‹œì ìœ¼ë¡œ GPUë¡œ ì˜¬ë¦¬ê¸° (ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ try/except)
if device == "cuda":
    try:
        yolo.to(device)
    except Exception as e:
        print("âš ï¸ YOLO .to(cuda) ì‹¤íŒ¨, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰:", e)

# SAM ë¡œë“œ
sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_BASE_CKPT)

# Fine-tuned decoderê°€ ìˆìœ¼ë©´ ë¡œë“œ
if os.path.isfile(SAM_DECODER_PTH):
    state = torch.load(SAM_DECODER_PTH, map_location="cpu")
    sam.mask_decoder.load_state_dict(state, strict=True)
    print(f"âœ… Loaded fine-tuned SAM decoder: {SAM_DECODER_PTH}")
else:
    print(f"âš ï¸ Fine-tuned decoder for '{fruit}' not found, using base SAM only.")

# SAMì„ deviceë¡œ ì˜¬ë¦¬ê¸°
sam.to(device)
predictor = SamPredictor(sam)

# ì‹¤ì œë¡œ ì–´ë–¤ ë””ë°”ì´ìŠ¤ì— ì˜¬ë¼ê°”ëŠ”ì§€ í™•ì¸ìš© ì¶œë ¥
try:
    yolo_device = next(yolo.model.parameters()).device
except Exception:
    # ultralytics ë²„ì „/êµ¬ì¡°ì— ë”°ë¼ model ì ‘ê·¼ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬
    yolo_device = "unknown"

sam_device = next(sam.parameters()).device

print("YOLO device:", yolo_device)
print("SAM  device:", sam_device)
print("==============================================")


# ===============================================
# í´ë” ìƒì„± ìœ í‹¸ (ì›ë³¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë³µì œ)
# ===============================================
def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

def mirror_structure(image_path, root_input=INPUT_DIR, root_output=OUTPUT_DIR):
    """
    INPUT_DIR ë‚´ë¶€ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ OUTPUT_DIR í•˜ìœ„ì— ë°˜ì˜
    ì˜ˆ)
      INPUT_DIR/2025ì°¸ì™¸/10ë„/xxx.png
      â†’ OUTPUT_DIR/melon/crop/2025ì°¸ì™¸/10ë„/...
    """
    rel_path = os.path.relpath(os.path.dirname(image_path), root_input)
    crop_dir = os.path.join(root_output, fruit, "crop", rel_path)
    full_dir = os.path.join(root_output, fruit, "full", rel_path)

    ensure_dir(os.path.join(crop_dir, "cutout_webp"))
    ensure_dir(os.path.join(crop_dir, "crop_rgb"))
    ensure_dir(os.path.join(crop_dir, "crop_mask"))
    ensure_dir(os.path.join(full_dir, "full_webp"))
    ensure_dir(os.path.join(full_dir, "full_mask"))

    return crop_dir, full_dir


# ===============================================
# YOLO â†’ SAM ì»·ì•„ì›ƒ
# ===============================================
def yolo_sam_cutout(image_path):
    print(f"â–¶ Processing {os.path.basename(image_path)}")

    # ì´ë¯¸ì§€ ë¡œë”©
    img = cv2.imread(image_path)
    if img is None:
        print(f"âš ï¸ Failed to read: {image_path}")
        return 0

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # YOLO ì¶”ë¡  (device ëª…ì‹œ)
    results = yolo.predict(
        source=img_rgb,
        conf=0.3,
        verbose=False,
        device=device  # cuda ë˜ëŠ” cpu
    )

    if not results or results[0].boxes is None or len(results[0].boxes) == 0:
        print(f"âš ï¸ No boxes detected: {image_path}")
        return 0

    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)
    print(f"ğŸ” Detected {len(boxes)} boxes in {os.path.basename(image_path)}")

    crop_dir, full_dir = mirror_structure(image_path)
    count = 0

    # í•œ ì´ë¯¸ì§€ì—ì„œ ê°ì§€ëœ boxë“¤ì— ëŒ€í•´ SAM ì„¸ê·¸ë©˜í…Œì´ì…˜
    predictor.set_image(img_rgb)  # â† ì´ë¯¸ì§€ë§ˆë‹¤ í•œ ë²ˆë§Œ ì„¸íŒ…

    for i, box in enumerate(boxes):
        x1, y1, x2, y2 = box

        input_box = np.array([x1, y1, x2, y2])
        masks, scores, _ = predictor.predict(
            box=input_box,
            multimask_output=True
        )
        best_mask = masks[np.argmax(scores)].astype(np.uint8)

        base = os.path.splitext(os.path.basename(image_path))[0]

        # 1ï¸âƒ£ Crop ì¤‘ì‹¬í˜• (box ì˜ì—­ë§Œ ì˜ë¼ì„œ RGBA)
        crop_rgb = img[y1:y2, x1:x2]
        mask_crop = best_mask[y1:y2, x1:x2] * 255
        rgba_crop = cv2.cvtColor(crop_rgb, cv2.COLOR_BGR2BGRA)
        rgba_crop[:, :, 3] = mask_crop

        cv2.imwrite(
            f"{crop_dir}/cutout_webp/{base}_{i}.webp",
            rgba_crop,
            [cv2.IMWRITE_WEBP_QUALITY, 95]
        )
        # í•„ìš”í•˜ë©´ RGBë„ ì €ì¥í•˜ê³  ì‹¶ì„ ë•Œ ì£¼ì„ í•´ì œ
        # cv2.imwrite(f"{crop_dir}/crop_rgb/{base}_{i}.png", crop_rgb)
        cv2.imwrite(f"{crop_dir}/crop_mask/{base}_{i}.png", mask_crop)

        # 2ï¸âƒ£ Full-maskí˜• (ì›ë³¸ í¬ê¸° ìœ ì§€, ì•ŒíŒŒë§Œ ë§ˆìŠ¤í¬ë¡œ)
        mask_full = best_mask * 255
        rgba_full = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
        rgba_full[:, :, 3] = mask_full

        cv2.imwrite(
            f"{full_dir}/full_webp/{base}_{i}.webp",
            rgba_full,
            [cv2.IMWRITE_WEBP_QUALITY, 95]
        )
        cv2.imwrite(f"{full_dir}/full_mask/{base}_{i}.png", mask_full)

        count += 1

    print(f"âœ… Saved {count} cutouts (crop+full) for {os.path.basename(image_path)}")
    return count


# ===============================================
# ì‹¤í–‰
# ===============================================
def main():
    images = []
    for root, _, files in os.walk(INPUT_DIR):
        for f in files:
            if f.lower().endswith((".jpg", ".png")):
                images.append(os.path.join(root, f))

    print(f"ğŸ“‚ Found {len(images)} images under INPUT_DIR = {INPUT_DIR}")
    total = 0

    for f in tqdm(images, desc=f"Processing ({fruit})"):
        n = yolo_sam_cutout(f)
        total += n

    print(f"âœ… Total cutouts saved for '{fruit}': {total}")

if __name__ == "__main__":
    main()
