# -*- coding: utf-8 -*-
"""
YOLO â†’ SAM ì»·ì•„ì›ƒ ìë™í™” (dual mode + directory mirroring)
==========================================================
1ï¸âƒ£ YOLOê°€ fruit box/mask íƒì§€
2ï¸âƒ£ SAMì´ YOLO boxë¥¼ seedë¡œ ë°›ì•„ ì •ë°€ ê²½ê³„ ìƒì„±
3ï¸âƒ£ ë‘ ê°€ì§€ ë²„ì „ ë™ì‹œ ì €ì¥:
    - crop ì¤‘ì‹¬í˜• (ê³¼ì¼ ì¤‘ì‹¬)
    - full-maskí˜• (ì›ë³¸ í¬ê¸° ìœ ì§€)
4ï¸âƒ£ ì›ë³¸ images_allì˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ cutout_resultsì—ë„ ê·¸ëŒ€ë¡œ ìœ ì§€
----------------------------------------------------------
í´ë” êµ¬ì¡° ì˜ˆì‹œ:
models/
 â”œâ”€â”€ melon/
 â”‚    â”œâ”€â”€ yolo_melon.pt
 â”‚    â”œâ”€â”€ sam_vit_b_01ec64.pth
 â”‚    â””â”€â”€ sam_mask_decoder_melon_final.pth
 â”œâ”€â”€ apple/
 â”‚    â”œâ”€â”€ yolo_apple.pt
 â”‚    â”œâ”€â”€ sam_vit_b_01ec64.pth
 â”‚    â””â”€â”€ sam_mask_decoder_apple_final.pth
"""

import os, cv2, torch, numpy as np
from ultralytics import YOLO
from segment_anything import sam_model_registry, SamPredictor
from tqdm import tqdm

# ===============================================
# ì„¤ì •
# ===============================================

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ê¸°ì¤€
current_dir = os.path.dirname(os.path.abspath(__file__))

# C# ë˜ëŠ” ì»¤ë§¨ë“œë¼ì¸ì—ì„œ --fruit ì˜µì…˜ìœ¼ë¡œ ì „ë‹¬ ê°€ëŠ¥í•˜ê²Œ
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--fruit", type=str, default=None, help="Fruit name (melon/apple/mandarin/garlic/onion...)")
args = parser.parse_args()

if args.fruit:
    fruit = args.fruit.lower()
else:
    # C#ì—ì„œ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë©´ ìƒìœ„ í´ë”ëª… ì‚¬ìš© (ì˜ˆ: ./melon/sam_pipeline.py)
    fruit = os.path.basename(os.path.dirname(current_dir)).lower()

# ëª¨ë¸ ë””ë ‰í† ë¦¬
MODEL_DIR = os.path.join(current_dir, "models", fruit)
if not os.path.exists(MODEL_DIR):
    print(f"âš ï¸ Model folder not found: {MODEL_DIR}")
    print("âŒ Please create models/{fruit}/ and put .pt/.pth files inside.")
    exit(1)

YOLO_WEIGHT = os.path.join(MODEL_DIR, f"yolo_{fruit}.pt")
SAM_BASE_CKPT = os.path.join(MODEL_DIR, "sam_vit_b_01ec64.pth")
SAM_DECODER_PTH = os.path.join(MODEL_DIR, f"sam_mask_decoder_{fruit}_final.pth")

INPUT_DIR = os.path.join(current_dir, "images_all")
OUTPUT_DIR = os.path.join(current_dir, "cutout_results")

device = "cuda" if torch.cuda.is_available() else "cpu"

# ===============================================
# ëª¨ë¸ ë¡œë“œ
# ===============================================

print(f"ğŸš€ Loading YOLO + SAM models for '{fruit}'...")

# YOLO ë¡œë“œ
if not os.path.isfile(YOLO_WEIGHT):
    print(f"âŒ YOLO weight not found: {YOLO_WEIGHT}")
    exit(1)

yolo = YOLO(YOLO_WEIGHT)

# SAM ëª¨ë¸ ë¡œë“œ
SAM_MODEL_TYPE = "vit_b"
if not os.path.isfile(SAM_BASE_CKPT):
    print(f"âŒ SAM base checkpoint not found: {SAM_BASE_CKPT}")
    exit(1)

sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_BASE_CKPT)

# fine-tuned decoder ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.isfile(SAM_DECODER_PTH):
    try:
        state = torch.load(SAM_DECODER_PTH, map_location="cpu")
        sam.mask_decoder.load_state_dict(state, strict=True)
        print(f"âœ… Loaded fine-tuned SAM decoder: {SAM_DECODER_PTH}")
    except Exception as e:
        print(f"âš ï¸ Decoder load failed ({SAM_DECODER_PTH}): {e}")
else:
    print(f"âš ï¸ Fine-tuned decoder for '{fruit}' not found, using base SAM only.")

sam.to(device)
predictor = SamPredictor(sam)

# ===============================================
# ìœ í‹¸ í•¨ìˆ˜
# ===============================================

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)

def mirror_structure(image_path, root_input=INPUT_DIR, root_output=OUTPUT_DIR):
    """
    images_all ë‚´ë¶€ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ cutout_results í•˜ìœ„ì— ë°˜ì˜
    """
    rel_path = os.path.relpath(os.path.dirname(image_path), root_input)
    crop_dir = os.path.join(root_output, fruit, "crop", rel_path)
    full_dir = os.path.join(root_output, fruit, "full", rel_path)

    ensure_dir(os.path.join(crop_dir, "cutout_webp"))
    ensure_dir(os.path.join(crop_dir, "crop_mask"))
    ensure_dir(os.path.join(full_dir, "full_webp"))
    ensure_dir(os.path.join(full_dir, "full_mask"))

    return crop_dir, full_dir

# ===============================================
# YOLO â†’ SAM ì»·ì•„ì›ƒ
# ===============================================

def yolo_sam_cutout(image_path):
    print(f"â–¶ Processing {os.path.basename(image_path)}")
    img = cv2.imread(image_path)
    if img is None:
        print(f"âš ï¸ Failed to read: {image_path}")
        return 0

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = yolo.predict(source=img_rgb, conf=0.3, verbose=False)

    if not results or results[0].boxes is None or len(results[0].boxes) == 0:
        print(f"âš ï¸ No boxes detected: {image_path}")
        return 0

    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)
    print(f"ğŸ” Detected {len(boxes)} boxes")

    crop_dir, full_dir = mirror_structure(image_path)
    count = 0

    for i, box in enumerate(boxes):
        x1, y1, x2, y2 = box
        predictor.set_image(img_rgb)
        input_box = np.array([x1, y1, x2, y2])
        masks, scores, _ = predictor.predict(box=input_box, multimask_output=True)
        best_mask = masks[np.argmax(scores)].astype(np.uint8)

        base = os.path.splitext(os.path.basename(image_path))[0]

        # 1ï¸âƒ£ Crop ì¤‘ì‹¬í˜•
        crop_rgb = img[y1:y2, x1:x2]
        mask_crop = best_mask[y1:y2, x1:x2] * 255
        rgba_crop = cv2.cvtColor(crop_rgb, cv2.COLOR_BGR2BGRA)
        rgba_crop[:, :, 3] = mask_crop

        cv2.imwrite(
            f"{crop_dir}/cutout_webp/{base}_{i}.webp",
            rgba_crop,
            [cv2.IMWRITE_WEBP_QUALITY, 95]
        )
        cv2.imwrite(f"{crop_dir}/crop_mask/{base}_{i}.png", mask_crop)

        # 2ï¸âƒ£ Full-maskí˜•
        mask_full = best_mask * 255
        rgba_full = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
        rgba_full[:, :, 3] = mask_full

        cv2.imwrite(
            f"{full_dir}/full_webp/{base}_{i}.webp",
            rgba_full,
            [cv2.IMWRITE_WEBP_QUALITY, 95]
        )
        cv2.imwrite(f"{full_dir}/full_mask/{base}_{i}.png", mask_full)

        count += 1

    print(f"âœ… Saved {count} cutouts (crop+full) for {os.path.basename(image_path)}")
    return count

# ===============================================
# ì‹¤í–‰
# ===============================================

def main():
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ Input folder not found: {INPUT_DIR}")
        return

    images = []
    for root, _, files in os.walk(INPUT_DIR):
        for f in files:
            if f.lower().endswith((".jpg", ".png")):
                images.append(os.path.join(root, f))

    if not images:
        print(f"âš ï¸ No images found under {INPUT_DIR}")
        return

    total = 0
    for f in tqdm(images, desc=f"Processing ({fruit})"):
        n = yolo_sam_cutout(f)
        total += n

    print(f"âœ… Total cutouts saved for '{fruit}': {total}")

if __name__ == "__main__":
    main()
